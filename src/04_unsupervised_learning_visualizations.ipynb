{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#unsupervised learning methods\n",
    "# Feature agglomeration uses agglomerative(or hierarchical) clustering to group similar features, so it has its own dimensionality reduction technique\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, FeatureAgglomeration, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# dimensionality reduction methods\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model scores\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, calinski_harabasz_score\n",
    "import setuptools\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin in patient level file label encoded\n",
    "path = \"../data/clean\"\n",
    "df_lab_enc = pd.read_pickle(f\"{path}/patient_level_lab_enc.pkl\")\n",
    "df = pd.read_pickle(f\"{path}/patient_level_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin icd10 mapper\n",
    "mapper_path = \"../data/mappers\"\n",
    "icd10_mapper = pd.read_pickle(f\"{mapper_path}/icd10.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f7c91",
   "metadata": {},
   "source": [
    "Word Cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65d957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc942709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = pd.read_pickle(f\"{path}/patient_level.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge primary diagnosis column back onto data now that it has been through learning\n",
    "df_patient = df_patient[['patient_medicare_number', 'age', 'combined_principal_diagnosis_ls', 'combined_hcpcs_ls']]\n",
    "# dropping data so the dataset is the same as the end dataset in 04_created_unsupervised_features\n",
    "df_patient = df_patient[df_patient['age'].notnull()]\n",
    "df_patient['ls_len'] = df_patient['combined_hcpcs_ls'].str.len()\n",
    "df_patient = df_patient[df_patient['ls_len'] < 1000]\n",
    "df_unsupervised = pd.concat([df_patient.reset_index(drop=True), df.reset_index(drop=True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsupervised.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52512d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsupervised['principal_unq'] = df_unsupervised['combined_principal_diagnosis_ls'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsupervised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create work cloud column of diagnosis descriptions\n",
    "\n",
    "for index, row in df_unsupervised.iterrows():\n",
    "\n",
    "    #print(row['principal_unq'])\n",
    "    if len(row['principal_unq']) > 1:\n",
    "        row_ls = []\n",
    "        for code in row['principal_unq']:\n",
    "            #print(code)\n",
    "            if icd10_mapper['CODE'].isin([code]).any():\n",
    "                ind = icd10_mapper[icd10_mapper['CODE'].str.contains(code)].index[0].item()\n",
    "                #print(ind)\n",
    "                text = icd10_mapper.loc[ind, 'SHORT DESCRIPTION'].split(' ')[0:4]\n",
    "                #print(f\"text {text}\") \n",
    "            #row_ls.append(text)\n",
    "            #print(text)\n",
    "            row_ls = row_ls + text\n",
    "        #print(row_ls)\n",
    "        #row_ls = [ word for word in row_ls if word != ',']\n",
    "        row_ls = [ word.strip(\", '\") for word in row_ls if word.strip(\", '\") not in ['unspecified', 'Unspecified', 'unsp', 'the', 'as', 'of', 'or', 'w', 'w/o', 'in', 'Acute', 'Chronic', 'Essential', '(primary)']]\n",
    "        #print(row_ls)\n",
    "        df_unsupervised.at[index, 'word_cloud'] = str(set(row_ls))\n",
    "        # df_unsupervised.at[index, 'word_cloud']= pd.Series([row_ls] * len(df_unsupervised))\n",
    "        # df_unsupervised.assign(word_cloud =  [row_ls for i in df_unsupervised.index])\n",
    "\n",
    "    else:\n",
    "        #print(code)\n",
    "        if icd10_mapper['CODE'].str.contains(code).any():\n",
    "            ind = icd10_mapper[icd10_mapper['CODE'].str.contains(code)].index[0].item()\n",
    "            #print(ind)\n",
    "            text = icd10_mapper.loc[ind, 'SHORT DESCRIPTION'].split( )[0:4]\n",
    "            text = [ word for word in text if word not in ['unspecified', 'Unspecified', 'as', 'of', 'or', 'w', 'w/o', 'Acute', 'Chronic', 'Essential', '(primary)']]\n",
    "            print(f\"text {text}\")\n",
    "            df_unsupervised.at[index, 'word_cloud'] = str(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage breakdown\n",
    "vals = df_unsupervised['word_cloud'].value_counts(normalize=True) * 100\n",
    "pd.DataFrame({\n",
    "  'age_breakdown': vals\n",
    "}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsupervised.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01cc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 9\n",
    "for cluster in range(0,n_clusters):\n",
    "    df_cluster = df_unsupervised[df_unsupervised['cluster'] == cluster]\n",
    "    diag_cloud = df_cluster['word_cloud'].head(100).apply(str).str.cat(sep=', ')\n",
    "    #Instantiate wordcloud object and use method to feed it our corpus\n",
    "    wc = WordCloud().generate_from_text(diag_cloud)\n",
    "\n",
    "    #Use matplotlib.pyplot to display the fitted wordcloud\n",
    "    #Turn axis off to get rid of axis numbers\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b30380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
