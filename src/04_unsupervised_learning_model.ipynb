{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Unsupervised Models\n",
    "## 04_unsupervised_model_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 28/09/2025   | Adrienne | Update | Creating models |\n",
    "| 05/10/2025 | Adrienne | Update | Created baseline model with KMeans |\n",
    "| 07.10.2025 | Adrienne | Update | Added code for wordcloud visualization |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#unsupervised learning methods\n",
    "# Feature agglomeration uses agglomerative(or hierarchical) clustering to group similar features, so it has its own dimensionality reduction technique\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, FeatureAgglomeration, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# dimensionality reduction methods\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model scores\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/clean\"\n",
    "\n",
    "df_lab_enc = pd.read_pickle(f\"{path}/patient_level_lab_enc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = pd.read_pickle(f\"{path}/patient_level.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_path = \"../data/mappers\"\n",
    "icd10_mapper = pd.read_pickle(f\"{mapper_path}/icd10.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "\n",
    "We will create a baseline model using the label encoded patient level file.  Variations on the model will be added and then performance compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model - KMeans\n",
    "\n",
    "Todo: \n",
    "- find optimal clusters\n",
    "- examine most important feature by principal component\n",
    " - create graph of clusters with principal components\n",
    " - optimize any model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_lab_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Calculate the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "feature_names = df_lab_enc.columns\n",
    "feature_contributions = pd.DataFrame(components, columns=feature_names)\n",
    "\n",
    "print(feature_contributions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "\n",
    "# Plot the explained variance ratio in the first subplot\n",
    "ax1.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio)\n",
    "ax1.set_xlabel(\"Principal Component\")\n",
    "ax1.set_ylabel(\"Explained Variance Ratio\")\n",
    "ax1.set_title(\"Explained Variance Ratio by Principal Component\")\n",
    "\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot the cumulative explained variance in the second subplot\n",
    "ax2.plot(\n",
    "    range(1, len(cumulative_explained_variance) + 1),\n",
    "    cumulative_explained_variance,\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax2.set_xlabel(\"Number of Principal Components\")\n",
    "ax2.set_ylabel(\"Cumulative Explained Variance\")\n",
    "ax2.set_title(\"Cumulative Explained Variance by Principal Components\")\n",
    "\n",
    "# Display the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of components\n",
    "n_pcs= pca.components_.shape[0]\n",
    "\n",
    "# get the index of the most important feature on EACH component i.e. largest absolute value\n",
    "# using LIST COMPREHENSION HERE\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "initial_feature_names = df_lab_enc.columns\n",
    "\n",
    "# get the names\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "# using LIST COMPREHENSION HERE AGAIN\n",
    "dic = {'PC{}'.format(i+1): most_important_names[i] for i in range(n_pcs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataframe - investigate \n",
    "df = pd.DataFrame(sorted(dic.items()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = pd.DataFrame(data= X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(principal_df[0], principal_df[1])\n",
    "plt.title('PCA Result')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans code\n",
    "kmeans = KMeans(init = 'random', n_clusters=12, n_init=10, random_state = 0) \n",
    "model = kmeans.fit(X_pca) \n",
    "model.n_iter_\n",
    "labels = model.labels_\n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/vnb5cqf52l31_n7r6zv3j6z80000gn/T/ipykernel_23972/1552931060.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lab_enc['cluster'] = labels\n"
     ]
    }
   ],
   "source": [
    "df_lab_enc['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at cluster values\n",
    "vals = df_lab_enc['cluster'].value_counts(normalize=True) * 100\n",
    "pd.DataFrame({\n",
    "  'cluster': vals\n",
    "}).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = pd.DataFrame(data= X_pca, columns = ['principal_comp_1', 'principal_comp_2', 'principal_comp_3', 'principal_comp_4', 'principal_comp_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1',fontsize=20)\n",
    "plt.ylabel('Principal Component - 2',fontsize=20)\n",
    "plt.title(\"XXX\",fontsize=20)\n",
    "targets = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "#targets = [ 0, 1, 2, 3]\n",
    "colors = ['r', 'g', 'b', 'y', 'r', 'g', 'b', 'y', 'r', 'g', 'b', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = df_lab_enc['cluster'] == target\n",
    "    print(indicesToKeep)\n",
    "    plt.scatter(principal_df.loc[indicesToKeep, 'principal_comp_1']\n",
    "               , principal_df.loc[indicesToKeep, 'principal_comp_2'], c = color, s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x= df_lab_enc.iloc[:, 2], y=df_lab_enc.iloc[:, 3], c= model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x= df_lab_enc.loc[:, 'hcpcs_0_enc'], y=df_lab_enc.loc[:, 'number_of_claims'], c= model.labels_)\n",
    "# plt.xlabel('Annual Income (k$)')\n",
    "# plt.ylabel('Spending Score (1-100)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cluster centers: centroids\n",
    "centroids = model.cluster_centers_# Assign the columns of centroids: centroids_x, centroids_y\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]# Make a scatter plot of centroids_x and centroids_y\n",
    "plt.scatter(centroids_x,centroids_y,marker='D',s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cluster in enumerate(clusters):\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=cluster, label=f'Cluster {i+1}')\n",
    "plt.scatter(*centroids, c='red', marker='x', s=200, label='Centroids')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for AgglomerativeClustering, FeatureAgglomerization and DBScan\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "labels = agg_clustering.fit_predict(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guassian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM code\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=3, random_state=0)\n",
    "gmm.fit(X)\n",
    "labels = gmm.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow method\n",
    "\n",
    "# works for all sklearn unsupervised model evaluation metrics with DBSCAN\n",
    "score = silhouette_score(X_train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example grid search\n",
    "\n",
    "param_grid = {n_components: [2, 5, 8, 10]} # easily add another parameter to this structure\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=KMeans(random_state=42, n_init='auto'),\n",
    "    param_grid=param_grid,\n",
    "    scoring=silhouette_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations:\n",
    "\n",
    "word cloud \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/vnb5cqf52l31_n7r6zv3j6z80000gn/T/ipykernel_23972/538535764.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_patient_test['principal_unq'] = df_patient_test['combined_principal_diagnosis_ls'].apply(lambda x: list(set(x)))\n"
     ]
    }
   ],
   "source": [
    "# merge primary diagnosis column back onto data now that it has been through learning\n",
    "df_patient_test = df_patient[['patient_medicare_number', 'combined_principal_diagnosis_ls']]\n",
    "\n",
    "df_patient_test['principal_unq'] = df_patient_test['combined_principal_diagnosis_ls'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>SHORT DESCRIPTION</th>\n",
       "      <th>LONG DESCRIPTION</th>\n",
       "      <th>NF EXCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A001</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A009</td>\n",
       "      <td>Cholera, unspecified</td>\n",
       "      <td>Cholera, unspecified</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0100</td>\n",
       "      <td>Typhoid fever, unspecified</td>\n",
       "      <td>Typhoid fever, unspecified</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0101</td>\n",
       "      <td>Typhoid meningitis</td>\n",
       "      <td>Typhoid meningitis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CODE                                  SHORT DESCRIPTION  \\\n",
       "0   A000  Cholera due to Vibrio cholerae 01, biovar chol...   \n",
       "1   A001    Cholera due to Vibrio cholerae 01, biovar eltor   \n",
       "2   A009                               Cholera, unspecified   \n",
       "3  A0100                         Typhoid fever, unspecified   \n",
       "4  A0101                                 Typhoid meningitis   \n",
       "\n",
       "                                    LONG DESCRIPTION NF EXCL  \n",
       "0  Cholera due to Vibrio cholerae 01, biovar chol...     NaN  \n",
       "1    Cholera due to Vibrio cholerae 01, biovar eltor     NaN  \n",
       "2                               Cholera, unspecified     NaN  \n",
       "3                         Typhoid fever, unspecified     NaN  \n",
       "4                                 Typhoid meningitis     NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd10_mapper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C50929', 'J45909', 'J209', 'C50919']\n",
      "C50929\n",
      "Index([1526], dtype='int64')\n",
      "text 1526    Malignant neoplasm of unsp site of unspecified...\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "J45909\n",
      "Index([10724], dtype='int64')\n",
      "text 10724    Unspecified asthma, uncomplicated\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "J209\n",
      "Index([10625], dtype='int64')\n",
      "text 10625    Acute bronchitis, unspecified\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "C50919\n",
      "Index([1523], dtype='int64')\n",
      "text 1523    Malignant neoplasm of unsp site of unspecified...\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "[patient_medicare_number                                                  1S00E00AA53\n",
      "combined_principal_diagnosis_ls    [C50929, J45909, C50929, C50929, C50929, J4590...\n",
      "principal_unq                                         [C50929, J45909, J209, C50919]\n",
      "principal_text                                                                   nan\n",
      "Name: 168, dtype: object]\n",
      "[patient_medicare_number                                                  1S00E00AA53\n",
      "combined_principal_diagnosis_ls    [C50929, J45909, C50929, C50929, C50929, J4590...\n",
      "principal_unq                                         [C50929, J45909, J209, C50919]\n",
      "principal_text                                                                   nan\n",
      "Name: 168, dtype: object, patient_medicare_number                                                  1S00E00AA53\n",
      "combined_principal_diagnosis_ls    [C50929, J45909, C50929, C50929, C50929, J4590...\n",
      "principal_unq                                         [C50929, J45909, J209, C50919]\n",
      "principal_text                                                                   nan\n",
      "Name: 168, dtype: object]\n",
      "['Z3480', 'J0190', 'J0301', 'J209', 'E119', 'K810']\n",
      "Z3480\n",
      "Index([], dtype='int64')\n",
      "text Series([], Name: SHORT DESCRIPTION, dtype: object)\n",
      "J0190\n",
      "Index([10541], dtype='int64')\n",
      "text 10541    Acute sinusitis, unspecified\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "J0301\n",
      "Index([10547], dtype='int64')\n",
      "text 10547    Acute recurrent streptococcal tonsillitis\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "J209\n",
      "Index([10625], dtype='int64')\n",
      "text 10625    Acute bronchitis, unspecified\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "E119\n",
      "Index([3578], dtype='int64')\n",
      "text 3578    Type 2 diabetes mellitus without complications\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "K810\n",
      "Index([11660], dtype='int64')\n",
      "text 11660    Acute cholecystitis\n",
      "Name: SHORT DESCRIPTION, dtype: object\n",
      "[patient_medicare_number                                                  1S00E00AA54\n",
      "combined_principal_diagnosis_ls    [E119, E119, E119, E119, E119, E119, E119, E11...\n",
      "principal_unq                                [Z3480, J0190, J0301, J209, E119, K810]\n",
      "principal_text                                                                   nan\n",
      "Name: 219, dtype: object]\n",
      "[patient_medicare_number                                                  1S00E00AA54\n",
      "combined_principal_diagnosis_ls    [E119, E119, E119, E119, E119, E119, E119, E11...\n",
      "principal_unq                                [Z3480, J0190, J0301, J209, E119, K810]\n",
      "principal_text                                                                   nan\n",
      "Name: 219, dtype: object, patient_medicare_number                                                  1S00E00AA54\n",
      "combined_principal_diagnosis_ls    [E119, E119, E119, E119, E119, E119, E119, E11...\n",
      "principal_unq                                [Z3480, J0190, J0301, J209, E119, K810]\n",
      "principal_text                                                                   nan\n",
      "Name: 219, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "# create work cloud column of diagnosis descriptions\n",
    "\n",
    "for index, row in df_patient_test.head(10).tail(2).iterrows():\n",
    "    principal_text_ls = []\n",
    "    print(row['principal_unq'])\n",
    "    if len(row['principal_unq']) > 1:\n",
    "        row_ls = []\n",
    "        for code in row['principal_unq']:\n",
    "            print(code)\n",
    "            if any(icd10_mapper[icd10_mapper['CODE'].str.contains(code)]):\n",
    "                ind = icd10_mapper[icd10_mapper['CODE'].str.contains(code)].index\n",
    "                print(ind)\n",
    "                text = icd10_mapper.loc[ind, 'SHORT DESCRIPTION']\n",
    "                print(f\"text {text}\")\n",
    "            else:\n",
    "                text = 'NaN'\n",
    "            row_ls.append(text)\n",
    "        principal_text_ls.append(row)\n",
    "        print(principal_text_ls)\n",
    "    else:\n",
    "        row_ls = []\n",
    "        print(code)\n",
    "        ind = icd10_mapper[icd10_mapper['CODE'].str.contains(code)].index[0]\n",
    "        print(ind)\n",
    "        text = icd10_mapper.loc[ind, 'SHORT DESCRIPTION']\n",
    "        print(f\"text {text}\")\n",
    "        row_ls.append(text)\n",
    "    principal_text_ls.append(row)\n",
    "    print(principal_text_ls)\n",
    "    \n",
    "    # principal_df = pd.DataFrame.from_records(principal_text_ls)\n",
    "    # test = pd.concat([df_patient_test, principal_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_medicare_number</th>\n",
       "      <th>combined_principal_diagnosis_ls</th>\n",
       "      <th>principal_unq</th>\n",
       "      <th>principal_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1S00E00AA10</td>\n",
       "      <td>[O039, O039, O039, B002, B002, B085, S8290X, J...</td>\n",
       "      <td>[J0190, B085, S8290X, O039, B002]</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1S00E00AA16</td>\n",
       "      <td>[E785, E785, E785, E785, B085, E785, E785, J01...</td>\n",
       "      <td>[J0190, E785, B085]</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1S00E00AA23</td>\n",
       "      <td>[J329, E785, J329, J029, J029, J329, J329, J32...</td>\n",
       "      <td>[J029, J209, E785, J329]</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1S00E00AA25</td>\n",
       "      <td>[E669, J0190, J0190, J329, J329, J329, J329, J...</td>\n",
       "      <td>[E669, J0190, S72009, J329, Z3400, J029]</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1S00E00AA32</td>\n",
       "      <td>[I10, J209, J209, J329, J0390, J209, J209, J20...</td>\n",
       "      <td>[I10, J0390, J209, J329]</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_medicare_number                    combined_principal_diagnosis_ls  \\\n",
       "1              1S00E00AA10  [O039, O039, O039, B002, B002, B085, S8290X, J...   \n",
       "18             1S00E00AA16  [E785, E785, E785, E785, B085, E785, E785, J01...   \n",
       "35             1S00E00AA23  [J329, E785, J329, J029, J029, J329, J329, J32...   \n",
       "64             1S00E00AA25  [E669, J0190, J0190, J329, J329, J329, J329, J...   \n",
       "89             1S00E00AA32  [I10, J209, J209, J329, J0390, J209, J209, J20...   \n",
       "\n",
       "                               principal_unq principal_text  \n",
       "1          [J0190, B085, S8290X, O039, B002]            nan  \n",
       "18                       [J0190, E785, B085]            nan  \n",
       "35                  [J029, J209, E785, J329]            nan  \n",
       "64  [E669, J0190, S72009, J329, Z3400, J029]            nan  \n",
       "89                  [I10, J0390, J209, J329]            nan  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patient_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate wordcloud object and use method to feed it our corpus\n",
    "wc = WordCloud().generate_from_text(rome_corpus)\n",
    "\n",
    "#Use matplotlib.pyplot to display the fitted wordcloud\n",
    "#Turn axis off to get rid of axis numbers\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
