{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_supervised_learning_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 30/10/2025   | Martin | Created   | Notebook created for supervised learning model | \n",
    "| 01/10/2025   | Martin | Add   | Added XGBoost and FFNN sections | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/clean\"\n",
    "df = pd.read_pickle(f\"{path}/patient_level.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_medicare_number</th>\n",
       "      <th>patient_first_name</th>\n",
       "      <th>patient_last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>number_of_claims</th>\n",
       "      <th>drg_ls</th>\n",
       "      <th>combined_diagnosis_ls</th>\n",
       "      <th>combined_hcpcs_ls</th>\n",
       "      <th>billablePeriod_start_ls</th>\n",
       "      <th>billablePeriod_end_ls</th>\n",
       "      <th>location_of_bill_ls</th>\n",
       "      <th>total_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1S00E00AA10</td>\n",
       "      <td>Brandon214</td>\n",
       "      <td>Roob72</td>\n",
       "      <td>female</td>\n",
       "      <td>1946-01-15</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[O039, O039, B085, B002, O039, J029]</td>\n",
       "      <td>[G0444, 99241, G0444, G9572]</td>\n",
       "      <td>[2013-04-23, 2016-01-15, 2020-06-02]</td>\n",
       "      <td>[2013-04-23, 2016-01-15, 2020-06-02]</td>\n",
       "      <td>[002]</td>\n",
       "      <td>15458.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1S00E00AA23</td>\n",
       "      <td>B.</td>\n",
       "      <td>Hagene</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[J329, E785, P292]</td>\n",
       "      <td>[G0444, G9572]</td>\n",
       "      <td>[2014-04-13]</td>\n",
       "      <td>[2014-04-13]</td>\n",
       "      <td>[]</td>\n",
       "      <td>840.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1S00E00AA25</td>\n",
       "      <td>Carlota980</td>\n",
       "      <td>Gamez720</td>\n",
       "      <td>female</td>\n",
       "      <td>1947-04-15</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[E669, D649, K635, O039, M810, J329, E669, D64...</td>\n",
       "      <td>[G0444, 99241]</td>\n",
       "      <td>[2012-07-18, 2021-11-23]</td>\n",
       "      <td>[2012-07-18, 2021-11-23]</td>\n",
       "      <td>[002]</td>\n",
       "      <td>85.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1S00E00AA32</td>\n",
       "      <td>Denny560</td>\n",
       "      <td>Watsica258</td>\n",
       "      <td>male</td>\n",
       "      <td>1945-06-09</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[P292, E669, I2510, B349, J329, I10, E669, I25...</td>\n",
       "      <td>[99241, 99241, 99241]</td>\n",
       "      <td>[2015-05-12, 2021-02-20, 2021-03-20]</td>\n",
       "      <td>[2015-05-12, 2021-02-20, 2021-03-20]</td>\n",
       "      <td>[002, 002, 002]</td>\n",
       "      <td>85.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1S00E00AA54</td>\n",
       "      <td>Lashawnda5</td>\n",
       "      <td>Greenfelder433</td>\n",
       "      <td>female</td>\n",
       "      <td>1950-12-23</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>[E119, R739, E781, E8881, D649, E11319, P292, ...</td>\n",
       "      <td>[G0444, 99241, 99241, 99241, 99241, G0444, 992...</td>\n",
       "      <td>[2012-10-27, 2013-01-26, 2014-06-21, 2014-07-2...</td>\n",
       "      <td>[2012-10-27, 2013-01-26, 2014-06-21, 2014-07-2...</td>\n",
       "      <td>[002, 002, 002, 002, 002, 002, 002, 002, 002, ...</td>\n",
       "      <td>142.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_medicare_number patient_first_name patient_last_name  gender  \\\n",
       "1              1S00E00AA10         Brandon214            Roob72  female   \n",
       "3              1S00E00AA23                 B.            Hagene  female   \n",
       "5              1S00E00AA25         Carlota980          Gamez720  female   \n",
       "6              1S00E00AA32           Denny560        Watsica258    male   \n",
       "10             1S00E00AA54         Lashawnda5    Greenfelder433  female   \n",
       "\n",
       "     birthdate  number_of_claims drg_ls  \\\n",
       "1   1946-01-15                 3     []   \n",
       "3          NaN                 1     []   \n",
       "5   1947-04-15                 2     []   \n",
       "6   1945-06-09                 3     []   \n",
       "10  1950-12-23                11     []   \n",
       "\n",
       "                                combined_diagnosis_ls  \\\n",
       "1                [O039, O039, B085, B002, O039, J029]   \n",
       "3                                  [J329, E785, P292]   \n",
       "5   [E669, D649, K635, O039, M810, J329, E669, D64...   \n",
       "6   [P292, E669, I2510, B349, J329, I10, E669, I25...   \n",
       "10  [E119, R739, E781, E8881, D649, E11319, P292, ...   \n",
       "\n",
       "                                    combined_hcpcs_ls  \\\n",
       "1                        [G0444, 99241, G0444, G9572]   \n",
       "3                                      [G0444, G9572]   \n",
       "5                                      [G0444, 99241]   \n",
       "6                               [99241, 99241, 99241]   \n",
       "10  [G0444, 99241, 99241, 99241, 99241, G0444, 992...   \n",
       "\n",
       "                              billablePeriod_start_ls  \\\n",
       "1                [2013-04-23, 2016-01-15, 2020-06-02]   \n",
       "3                                        [2014-04-13]   \n",
       "5                            [2012-07-18, 2021-11-23]   \n",
       "6                [2015-05-12, 2021-02-20, 2021-03-20]   \n",
       "10  [2012-10-27, 2013-01-26, 2014-06-21, 2014-07-2...   \n",
       "\n",
       "                                billablePeriod_end_ls  \\\n",
       "1                [2013-04-23, 2016-01-15, 2020-06-02]   \n",
       "3                                        [2014-04-13]   \n",
       "5                            [2012-07-18, 2021-11-23]   \n",
       "6                [2015-05-12, 2021-02-20, 2021-03-20]   \n",
       "10  [2012-10-27, 2013-01-26, 2014-06-21, 2014-07-2...   \n",
       "\n",
       "                                  location_of_bill_ls  total_value  \n",
       "1                                               [002]     15458.12  \n",
       "3                                                  []       840.21  \n",
       "5                                               [002]        85.55  \n",
       "6                                     [002, 002, 002]        85.55  \n",
       "10  [002, 002, 002, 002, 002, 002, 002, 002, 002, ...       142.58  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost List\n",
    "\n",
    "Get the cost of procedures from claims with single HCPCS based on the existing claims list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_list_from_hcpcs(df: pd.DataFrame, price_selection: str):\n",
    "  \"\"\"Retrieve the price of each HCPCS code from those claims that only have 1 code\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): Patient Level dataset\n",
    "      price_selection (str): Any aggregation function for group by (\"max\", \"min\", \"mean\"). \n",
    "          How to handle when multiple claims have the same singular code\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: Cost of each HCPCS\n",
    "  \"\"\"\n",
    "  temp = df.copy()\n",
    "  temp['hcpcs_len'] = temp['combined_hcpcs_ls'].str.len()\n",
    "\n",
    "  # Get only those with single HCPC values\n",
    "  cost = temp[temp['hcpcs_len'] == 1]\n",
    "\n",
    "  # Only the select only the hcpcs codes and total bill\n",
    "  cost['hcpcs_code'] = cost['combined_hcpcs_ls'].str[0]\n",
    "  cost = cost[['hcpcs_code', 'total_value']]\n",
    "\n",
    "  # Based on cost selection\n",
    "  cost = cost.groupby('hcpcs_code').agg(price_selection)\n",
    "  cost['total_value'] = np.round(cost['total_value'], 2)\n",
    "  cost = cost.reset_index()\n",
    "  cost = cost.rename({\n",
    "    'total_value': 'cost'\n",
    "  }, axis=1)\n",
    "\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_37640\\1920424403.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price['hcpcs_code'] = price['combined_hcpcs_ls'].str[0]\n"
     ]
    }
   ],
   "source": [
    "cost = get_price_list_from_hcpcs(df, price_selection='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hcpcs_code</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99221</td>\n",
       "      <td>5666.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99241</td>\n",
       "      <td>2370.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G0107</td>\n",
       "      <td>36515.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G0151</td>\n",
       "      <td>526.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G0152</td>\n",
       "      <td>1041.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hcpcs_code      cost\n",
       "0      99221   5666.37\n",
       "1      99241   2370.06\n",
       "2      G0107  36515.28\n",
       "3      G0151    526.33\n",
       "4      G0152   1041.51"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Assumption: All the data is already numerically encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform additional steps here\n",
    "# Might consider feature cross for sequence representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "\n",
    "Create train, validation and test splits in __stratified__ manner\n",
    "\n",
    "- Train: 70%\n",
    "- Validation: 15%\n",
    "- Test: 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values here\n",
    "train_size = 0.7\n",
    "test_size = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "train, temp = train_test_split(df, train_size=train_size, stratify=y, random_state=SEED)\n",
    "val, test = train_test_split(temp, train_size=val_size, stratify=y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = pd.concat([train, val], axis=0)\n",
    "y_strat = strat['target']\n",
    "X_strat = strat.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['target']\n",
    "y_train = train.drop('target', axis=1)\n",
    "\n",
    "X_val = val['target']\n",
    "y_val = val.drop('target', axis=1)\n",
    "\n",
    "X_test = test['target']\n",
    "y_test = test.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Common classification metrics:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score (weighted or micro)\n",
    "- ROC AUC Score (OVR + weighted)\n",
    "\n",
    "Plots:\n",
    "\n",
    "- Confusion Matrix\n",
    "- ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_score(y_true, y_pred):\n",
    "  acc = round(accuracy_score(y_true, y_pred), 4)\n",
    "  prec = round(precision_score(y_true, y_pred), 4)\n",
    "  recall = round(recall_score(y_true, y_pred), 4)\n",
    "  f1 = round(f1_score(y_true, y_pred, average=\"weighted\"), 4)\n",
    "  roc_auc = round(roc_auc_score(y_true, y_pred, average=\"weighted\", multi_class=\"ovr\"), 4)\n",
    "\n",
    "  return acc, prec, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, clf):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=clf.classes_\n",
    "  )\n",
    "\n",
    "  disp.plot(cmap=plt.cm.Blues)\n",
    "  plt.title(\"Confusion Matrix\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_AUC():\n",
    "  # TODO: Determine which method of comparison should be used\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Dummy Classifier\n",
    "\n",
    "Uses sklearns dummy classifier to test various baseline strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here\n",
    "strategy = \"most_frequent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=strategy)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "preds = dummy_clf.predict(X_val)\n",
    "metrics_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_val, preds, dummy_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression\n",
    "\n",
    "Simple logistic regression model for an improved baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = OneVsRestClassifier(LogisticRegression(random_state=SEED))\n",
    "# lr_model = OneVsOneClassifier(LogisticRegression(random_state=SEED))\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "preds = lr_model.predict(X_val)\n",
    "metrics_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_val, preds, lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For K-Fold shuffled stratified cross validation\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=SEED)\n",
    "lr_model = OneVsRestClassifier(LogisticRegression(random_state=SEED))\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "  print(f\"\\n========== Split {split_idx} ==========\")\n",
    "\n",
    "  X_strat_train, X_strat_val = X_strat[train_idx], X_strat[train_idx]\n",
    "  y_strat_train, y_strat_val = y_strat[train_idx], y_strat[train_idx]\n",
    "\n",
    "  lr_model.fit(X_strat_train, y_strat_train)\n",
    "\n",
    "  preds = lr_model.predict(X_strat_val)\n",
    "  metrics_score(pred, y_strat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Decision Tree / Random Forest\n",
    "\n",
    "Similar reason for decision tree except more interpretable. Random forest for boosting improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model tuning\n",
    "config = {\n",
    "  \"max_depth\": None,\n",
    "  \"min_samples_split\": 2,\n",
    "  \"min_samples_leaf\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(**config, random_state=SEED)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "preds = dt_model.predict(X_val)\n",
    "metrics_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_val, preds, dt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For K-Fold shuffled stratified cross validation\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=SEED)\n",
    "dt_model = OneVsRestClassifier(DecisionTreeClassifier(random_state=SEED))\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "  print(f\"\\n========== Split {split_idx} ==========\")\n",
    "\n",
    "  X_strat_train, X_strat_val = X_strat[train_idx], X_strat[train_idx]\n",
    "  y_strat_train, y_strat_val = y_strat[train_idx], y_strat[train_idx]\n",
    "\n",
    "  dt_model.fit(X_strat_train, y_strat_train)\n",
    "\n",
    "  preds = dt_model.predict(X_strat_val)\n",
    "  metrics_score(pred, y_strat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model tuning\n",
    "config = {\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": None,\n",
    "  \"min_samples_split\": 2,\n",
    "  \"min_samples_leaf\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(**config, random_state=SEED)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "preds = rf_model.predict(X_val)\n",
    "metrics_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For K-Fold shuffled stratified cross validation\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=SEED)\n",
    "rf_model = OneVsRestClassifier(DecisionTreeClassifier(random_state=SEED))\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "  print(f\"\\n========== Split {split_idx} ==========\")\n",
    "\n",
    "  X_strat_train, X_strat_val = X_strat[train_idx], X_strat[train_idx]\n",
    "  y_strat_train, y_strat_val = y_strat[train_idx], y_strat[train_idx]\n",
    "\n",
    "  rf_model.fit(X_strat_train, y_strat_train)\n",
    "\n",
    "  preds = rf_model.predict(X_strat_val)\n",
    "  metrics_score(pred, y_strat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: XGBoost\n",
    "\n",
    "Larger improvement over standard decision tree and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"num_class\": 10, # Change this based on number of cluster outputs\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": 2,\n",
    "  \"learning_rate\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(**config, objective=\"multi:softmax\" random_state=SEED)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "preds = xgb_model.predict(X_val)\n",
    "metrics_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance metrics in XGBoost Trees:\n",
    "\n",
    "- `gain` - A measure of the improvement in model performance or reduction in loss achieved by using a specific feature to split a node in a decision tree\n",
    "- `weight` - The number of times a feature is used to split the data across all trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance with built in XGBoost module\n",
    "feature_importance_gain = xgb_model.get_booster().get_score(importance_type='gain')\n",
    "print(\"Feature Importance (Gain):\")\n",
    "for feature, importance in feature_importance_gain.items():\n",
    "  print(f\"{feature}: {importance}\")\n",
    "\n",
    "feature_importance_weight = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "print(\"Feature Importance (Weight):\")\n",
    "for feature, importance in feature_importance_weight.items():\n",
    "  print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: FF Neural Network\n",
    "\n",
    "Trying this out if we have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.models\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, ReLU, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Tuning\n",
    "input_shape = (64, ) # Number of columns\n",
    "output_shape = 10 # Number of clusters (targets)\n",
    "optimizer = \"sgd\"\n",
    "loss = \"categorical_crossentropy\" # If target is one-hot encoded sparse_categorical_crossentropy\n",
    "num_epochs = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(input_shape)\n",
    "\n",
    "# 2 Layer MLP\n",
    "dense_layer_1 = Dense(64)(inputs)\n",
    "batch_norm_1 = BatchNormalization()(dense_layer_1)\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "dropout_1 = Dropout(rate=0.1)(relu_1)\n",
    "\n",
    "dense_layer_2 = Dense(64)(dropout_1)\n",
    "batch_norm_2 = BatchNormalization()(dense_layer_2)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "dropout_2 = Dropout(rate=0.1)(relu_2)\n",
    "\n",
    "outputs = Dense(output_shape, activation='softmax')(dropout_2)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,482</span> (37.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,482\u001b[0m (37.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,226</span> (36.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,226\u001b[0m (36.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=optimizer,\n",
    "  loss=loss,\n",
    "  metrics=[\n",
    "    keras.metrics.CategoricalAccuracy(),\n",
    "    keras.metrics.Precision(),\n",
    "    keras.metrics.Recall(),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  validation_data=[X_val, y_val],\n",
    "  epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature & Model Evaluation\n",
    "\n",
    "Have yet to decision visualisations and feature evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
